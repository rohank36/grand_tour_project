# COMP 400 Project

<div align="center">

**Offline Learning for Quadruped Locomotion using the Grand Tour Dataset**

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.4+-red.svg)

</div>

---

## Overview

This project implements **offline learning algorithms** for training quadruped locomotion policies on the [Grand Tour Dataset](https://huggingface.co/datasets/leggedrobotics/grand_tour_dataset) â€” a large-scale real-world dataset of ANYmal D robot trajectories. The trained policies are evaluated in the **Isaac Gym** physics simulator.

### Key Features

- ðŸ¤– **Multiple Offline RL Algorithms**: Vanilla BC, IQL, CQL, EDAC
- ðŸŽ¯ **Diffusion Policy Support**: Transformer-based diffusion policies for locomotion
- ðŸ”„ **End-to-end Pipeline**: From raw sensor data to trained policies
- ðŸ“Š **Isaac Gym Integration**: Online evaluation in high-fidelity simulation
- ðŸ“ˆ **Weights & Biases Logging**: Comprehensive experiment tracking

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Grand Tour Dataset                               â”‚
â”‚                    (Real-world ANYmal D trajectories)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Pipeline                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   download   â”‚â”€â”€â”€â–¶â”‚build_dataset_full_piplineâ”‚                      â”‚
â”‚  â”‚    .py       â”‚    â”‚        .py               â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Offline Dataset (HDF5)                              â”‚
â”‚         observations, actions, rewards, terminals, next_obs              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training + Online Evaluation                          â”‚
â”‚         (BC/IQL/CQL/EDAC/Diffusion) â†’ Isaac Gym (ANYmal D Flat)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

### Prerequisites

- Python 3.8+
- Isaac Gym Preview 4
- Hugging Face account (for dataset access)

### Setup

1. **Create project dir and clone the repository into project dir**
   ```bash
   mkdir project
   cd project
   git clone https://github.com/your-username/grand_tour_project.git .
   cd grand_tour_project
   ```

2. **Create virtual environment with python 3.8 and activate venv**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # or
   .\venv\Scripts\activate   # Windows
   ```

3. **Install Isaac Gym**
   ```bash
   # Download Isaac Gym Preview 4 from NVIDIA
   cd /path/to/isaacgym/python
   pip install -e .
   ```

4. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Install legged_gym (ANYmal D support)**
   ```bash
   pip install -e git+https://github.com/modanesh/legged_gym_anymal_d.git#egg=legged_gym
   ```

6. **Configure Hugging Face token**
   ```bash
   # Create .env file
   echo "HF_TOKEN=your_huggingface_token" > .env
   ```

---

## Data Pipeline

### 1. Download Grand Tour Dataset

Download real-world ANYmal D trajectories from Hugging Face:

```bash
python download.py
```

This downloads the following sensor topics:
- `anymal_state_odometry` â€” Robot pose and velocity
- `anymal_state_state_estimator` â€” Joint positions, velocities, contact states
- `anymal_imu` â€” IMU measurements
- `anymal_state_actuator` â€” Actuator commands
- `anymal_command_twist` â€” Velocity commands

### 2. Align Sensor Data and Build Offline RL Dataset

Convert aligned data to offline RL format compatible with Isaac Gym:

```bash
python build_dataset_full_pipeline.py
```

Note that if the aligned_data.zarr has already been created, you can comment out the `align_data()` call and just load the aligned data when building the dataset to save time. If it's your first time running it, make sure `align_data()` is uncommented in the file. 

**Output**: `offline_dataset_pp.hdf5` with:
- `observations` â€” 36D state vectors (or 48D with previous actions)
- `actions` â€” 12D joint position targets
- `rewards` â€” Computed using Isaac Gym reward functions
- `terminals` â€” Episode boundaries
- `next_observations` â€” Next state

### Observation Space (36 dimensions)

| Index | Description | Scale |
|-------|-------------|-------|
| 0-2 | Base linear velocity (body frame) | Ã— 2.0 |
| 3-5 | Base angular velocity (body frame) | Ã— 0.25 |
| 6-8 | Projected gravity | â€” |
| 9-11 | Commands [vx, vy, Ï‰_yaw] | Ã— [2.0, 2.0, 0.25] |
| 12-23 | Joint positions (offset from default) | Ã— 1.0 |
| 24-35 | Joint velocities | Ã— 0.05 |
| 36-47 | Prev Actions | | 

### Action Space (12 dimensions)

Joint position targets for the 12 DOF:
```
LF_HAA, LF_HFE, LF_KFE, RF_HAA, RF_HFE, RF_KFE,
LH_HAA, LH_HFE, LH_KFE, RH_HAA, RH_HFE, RH_KFE
```

To change the sensors used or which observations are built (e.g., if you want to remove prev actions or not), modify `build_offline_dataset()` in `build_dataset.py`.

---

## Training

To use a specific learning algorithm it suffices to do

```bash
python <algorithm_file.py>
e.g.,
python diffuseloco.py
python cql.py
```
The configuration file for the DiffuseLoco training is in `diffusion_policy/diffusion_policy/config/anymal_diffusion_policy.yaml`.

The configuration for the rest of the learning algorithms are in the respective learning files.

Modifying these configs allows you to choose which dataset to use, max training steps, learning rate etc.

Note that for DiffuseLoco, depending on how many observation dimensions there are (36 with no prev actions vs 48 with), the correct observation dimension should be put in the config file `anymal_diffusion_policy.yaml`

---

## Evaluation

All training scripts automatically evaluate in Isaac Gym every `eval_freq` steps and log the individual reward terms and the avg episode reward and length

---

## Project Structure

```
grand_tour_project/
â”œâ”€â”€ download.py              # Download Grand Tour dataset from HuggingFace
â”œâ”€â”€ align_data.py            # Align multi-sensor data to 50Hz
â”œâ”€â”€ build_dataset.py         # Build offline RL dataset (HDF5)
â”œâ”€â”€ build_dataset_full_pipeline.py  # End-to-end dataset building (calls align_data.py and build_dataset.py) 
â”‚
â”œâ”€â”€ vanilla_bc.py            # Vanilla Behavioral Cloning
â”œâ”€â”€ iql.py                   # Implicit Q-Learning
â”œâ”€â”€ cql.py                   # Conservative Q-Learning
â”œâ”€â”€ edac.py                  # Ensemble Diversified Actor Critic
â”‚
â”œâ”€â”€ eval_isaac_v2.py         # Isaac Gym online evaluation
â”œâ”€â”€ reward.py                # Reward function implementations
â”œâ”€â”€ utils.py                 # Utility functions
â”‚
â”œâ”€â”€ isaac_compatibility.py   # Grand Tour â†’ Isaac Gym data transforms
â”œâ”€â”€ grandtour_compatibility.py # Isaac Gym â†’ Grand Tour data transforms
â”‚
â”œâ”€â”€ diffusion_policy/        # Diffusion policy implementation
â”‚   â”œâ”€â”€ config/              # Hydra configuration files
â”‚   â”œâ”€â”€ dataset/             # Dataset loaders
â”‚   â”œâ”€â”€ model/               # Network architectures
â”‚   â”œâ”€â”€ policy/              # Policy implementations
â”‚   â””â”€â”€ workspace/           # Training workspaces
â”‚
â”œâ”€â”€ diffuseloco.py           # Diffusion policy training entry point
â”œâ”€â”€ compare_dataset_*.py     # Dataset analysis scripts to compare datasets
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

---

## Configuration


### Weights & Biases Integration

All training scripts log to W&B:

```python
project: "grand_tour"
```

View experiments at [wandb.ai](https://wandb.ai).

---

## Data Format Compatibility

### Observation Scaling

The project handles observation scaling between Grand Tour (raw) and Isaac Gym (scaled) formats:

| Component | Grand Tour | Isaac Gym Scale |
|-----------|------------|-----------------|
| Linear velocity | Raw | Ã— 2.0 |
| Angular velocity | Raw | Ã— 0.25 |
| Commands | Raw | Ã— [2.0, 2.0, 0.25] |
| Joint positions | Absolute | Offset from default |
| Joint velocities | Raw | Ã— 0.05 |

### Action Conversion

Actions are converted between formats using:
- **Grand Tour**: Absolute joint positions
- **Isaac Gym**: Normalized offsets from default positions

```python
# Grand Tour â†’ Isaac Gym
action_isaac = (action_gt - default_dof_pos) / action_scale

# Isaac Gym â†’ Grand Tour  
action_gt = action_isaac * action_scale + default_dof_pos
```
---

---

## Acknowledgments

- [Grand Tour Dataset](https://huggingface.co/datasets/leggedrobotics/grand_tour_dataset) by Leggedrobotics
- [Isaac Gym](https://developer.nvidia.com/isaac-gym) by NVIDIA
- [legged_gym_anymal_d](https://github.com/modanesh/legged_gym_anymal_d) for ANYmal D support
- [CORL](https://github.com/tinkoff-ai/CORL) for offline RL algorithm implementations
- [DiffuseLoco](https://github.com/HybridRobotics/DiffuseLoco) for transformer-based diffusion policies

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

